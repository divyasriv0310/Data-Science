{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from scipy.stats import chi2_contingency, mannwhitneyu, median_test, ttest_ind, kruskal\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing data \n",
    "ckd_df = pd.read_csv(r\"C:\\Users\\visha\\Desktop\\Dissertation\\Chronic_Kidney_Disease\\chronic_kidney_disease_full.csv\")\n",
    "ckd_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckd_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing '?' with NaN values\n",
    "ckd_df.replace('?', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckd_df = ckd_df.drop('id',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckd_df.columns = ['age','blood_pressure','specific_gravity','albumin','sugar','red_blood_cells','pus_cell','puss_cell_clumps','bacteria',\n",
    "                  'blood_glucose','blood_urea','serum_creatinine','sodium','potassium','haemoglobin','packed_cell_volume',\n",
    "                  'white_blood_cells_count','red_blood_cell_count','hypertension','diabetes_mellitus','coronary_artery_disease',\n",
    "                  'appetite','pedal_edema','anemia','chronic_kidney_disease']\n",
    "\n",
    "ckd_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckd_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since all the features are showing as object data type, converting necessary features to numeric as they should be\n",
    "columns_to_convert = ['age', 'blood_pressure', 'specific_gravity', 'albumin','sugar','blood_glucose', 'blood_urea', 'serum_creatinine', \n",
    "                      'sodium', 'potassium', 'haemoglobin', 'packed_cell_volume', \n",
    "                      'white_blood_cells_count', 'red_blood_cell_count']\n",
    "\n",
    "ckd_df[columns_to_convert] = ckd_df[columns_to_convert].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckd_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating categorical columns and numerical columns variables for further use\n",
    "cat_cols = []\n",
    "\n",
    "for col in ckd_df.columns:\n",
    "    if ckd_df[col].dtype == 'object':\n",
    "        cat_cols.append(col)\n",
    "\n",
    "\n",
    "\n",
    "num_cols = []\n",
    "\n",
    "for col in ckd_df.columns:\n",
    "    if ckd_df[col].dtype != 'object':\n",
    "        num_cols.append(col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for unique values in each feature to understand if data needs any further processing\n",
    "\n",
    "for col in cat_cols:\n",
    "    print(f'{col} feature has {ckd_df[col].unique()} values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in num_cols:\n",
    "    print(f'{col} feature has {ckd_df[col].unique()} values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#descriptive statistics\n",
    "ckd_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.style as style\n",
    "style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows, n_cols = (7,2)\n",
    "\n",
    "figure, axes = plt.subplots(nrows=n_rows, ncols=n_cols,figsize=(20, 50))\n",
    "figure.suptitle('\\nDistributions of Numerical Features', fontsize=60)\n",
    "\n",
    "for index, column in enumerate(num_cols):\n",
    "    \n",
    "    i,j = (index // n_cols), (index % n_cols)\n",
    "    \n",
    "    miss_perc=\"%.2f\"%(100*(1-(ckd_df[column].dropna().shape[0])/ckd_df.shape[0]))\n",
    "    \n",
    "    collabel=column+\"\\n({}% is missing)\".format(miss_perc)\n",
    "    \n",
    "    fig=sns.distplot(ckd_df[column], color=\"g\", label=collabel, norm_hist=True,\n",
    "    \n",
    "    ax=axes[i,j], kde_kws={\"lw\":4})\n",
    "    \n",
    "    fig=fig.legend(loc='best', fontsize=18)\n",
    "    \n",
    "    axes[i,j].set_ylabel(\"Probability Density\",fontsize='medium')\n",
    "    \n",
    "    axes[i,j].set_xlabel(None)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style.use('seaborn-darkgrid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_rows, n_cols = (6, 2)\n",
    "\n",
    "figure, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(30, 50))\n",
    "figure.suptitle('\\nCountplots of Categorical Features', fontsize=60)\n",
    "\n",
    "for index, column in enumerate(cat_cols):\n",
    "\n",
    "    i, j = index // n_cols, index % n_cols\n",
    "\n",
    "    miss_perc = \"%.2f\" % (100 * (1 - (ckd_df[column].dropna().shape[0]) / ckd_df.shape[0]))\n",
    "\n",
    "    collabel = column + \"\\n({}% is missing)\".format(miss_perc)\n",
    "\n",
    "    fig = sns.countplot(x=column, data=ckd_df, label=collabel, palette=sns.cubehelix_palette(rot=-.35, light=0.85, hue=1),\n",
    "\n",
    "    ax=axes[i, j])\n",
    "\n",
    "    axes[i, j].set_title(collabel, fontsize=30)\n",
    "\n",
    "    axes[i, j].set_xlabel(None)\n",
    "\n",
    "    axes[i, j].set_ylabel(\"Count\", fontsize=20)\n",
    "\n",
    "    axes[i, j].set_xticklabels(axes[i, j].get_xticklabels(), fontsize=28)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckd_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckd_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxplots to understand more about outliers \n",
    "\n",
    "n_rows, n_cols = (7,2)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(nrows=n_rows,ncols=n_cols,figsize=(18,25))\n",
    "\n",
    "\n",
    "for index,col in enumerate(num_cols):\n",
    "    [i,j] = index//n_cols, index%n_cols\n",
    "\n",
    "    fig = sns.boxplot(data=ckd_df,x=col,ax=axes[i,j],notch=True,flierprops={\"marker\": \"x\"},color=\"#B4E2B0\")\n",
    "    \n",
    "plt.tight_layout()   \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting target variable to numeric for correlation analysis\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "df[num_cols] = ckd_df[num_cols]\n",
    "\n",
    "df[\"target\"] = ckd_df[\"chronic_kidney_disease\"].map({'ckd':1,'notckd':0})\n",
    "\n",
    "df_cor = df.corr()\n",
    "\n",
    "mask = np.triu(np.ones_like(df_cor))\n",
    "\n",
    "sns.heatmap(data=df_cor,mask=mask,annot=True,linewidths=3,fmt='.2f')\n",
    "\n",
    "plt.tight_layout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###high positive correlations:\n",
    "1. blood-glucose and sugar \n",
    "2. packed_cell_volume and haemoglobin\n",
    "3. red_blood_cell_count and haemoglobin\n",
    "4. red_blood_cell_count and packed_cell_volume\n",
    "\n",
    "high negative correlations:\n",
    "1. specific_gravity and target\n",
    "2. haemoglobin and target\n",
    "3. packed_cell_volume and target\n",
    "4. red_blood_cell_count and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#violin plots and scatter plot to understand the correlation:\n",
    "def violin(col):\n",
    "    fig = sns.violinplot(ckd_df, y=col, x=\"chronic_kidney_disease\", box=True)\n",
    "    return plt.show()\n",
    "\n",
    "def scatter(col1, col2):\n",
    "    fig = sns.scatterplot(ckd_df, x=col1, y=col2, hue=\"chronic_kidney_disease\")\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. blood_glucose and sugar \n",
    "\n",
    "scatter(\"blood_glucose\",\"sugar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. packed_cell_volume and haemoglobin\n",
    "scatter(\"packed_cell_volume\",\"haemoglobin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. red_blood_cell_count and haemoglobin\n",
    "scatter(\"red_blood_cell_count\",\"haemoglobin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. red_blood_cell_count and packed_cell_volume\n",
    "scatter(\"red_blood_cell_count\",\"packed_cell_volume\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. specific_gravity and target\n",
    "violin(\"specific_gravity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. haemoglobin and target\n",
    "violin(\"haemoglobin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. packed_cell_volume and target\n",
    "violin(\"packed_cell_volume\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. red_blood_cell_count and target\n",
    "violin(\"red_blood_cell_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding \n",
    "ohe_data = pd.get_dummies(ckd_df,drop_first=True,prefix_sep=':',dtype=int,dummy_na=False)\n",
    "ohe_data.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the missing values have been converted in to 0s for cat columns, converting them back \n",
    "\n",
    "names={}\n",
    "for name in ckd_df.columns:\n",
    "    for ohe in ohe_data.columns:\n",
    "        if name+':' in ohe and name in cat_cols:\n",
    "            names[name]=ohe\n",
    "            for i in range(400):\n",
    "                if type(ckd_df.loc[i,name])!=str:\n",
    "                    if math.isnan(ckd_df.loc[i,name]):\n",
    "                        ohe_data.loc[i,ohe]=ckd_df.loc[i,name]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_cat_cols = list(ohe_data.columns.values)\n",
    "ohe_num_cols = ohe_cat_cols[:14]\n",
    "ohe_cat_cols = ohe_cat_cols[14:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_data.iloc[:,14:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(StandardScaler())\n",
    "print(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = [ohe_data]\n",
    "df1 = pd.DataFrame(pipe.fit_transform(ohe_data),columns = ohe_data.columns)\n",
    "df.append(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno\n",
    "\n",
    "msno.bar(ckd_df,color=\"turquoise\",sort=\"ascending\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN imputation \n",
    "\n",
    "imputer = KNNImputer(weights='distance',n_neighbors=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rrr = [ohe_data.to_numpy()]\n",
    "rrr.append(imputer.fit_transform(df[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = [rrr[0]]\n",
    "for i in range(1,len(rrr)):\n",
    "    arr.append(pipe[i-1].inverse_transform(rrr[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_df=[]\n",
    "for i in range(len(arr)):\n",
    "    imputed_df.append(pd.DataFrame(arr[i],columns=ohe_data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_data = imputed_df[1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_data.dropna().shape #no missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.bar(ohe_data,color=\"aquamarine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_data.dropna().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting categorical variables with target variable\n",
    "\n",
    "figure, axes = plt.subplots(6, 2,figsize=(50, 100))\n",
    "figure.suptitle('\\nCrossTabs of Categorical Variables with Target Variable', fontsize=70)\n",
    "\n",
    "for index, col in enumerate(cat_cols):\n",
    "    \n",
    "    i,j = (index // 2), (index % 2)\n",
    "    \n",
    "    sns.heatmap(pd.crosstab(ckd_df[col],ckd_df['chronic_kidney_disease']),\n",
    "                ax=axes[i,j],            \n",
    "                square='True',\n",
    "                cbar=False,\n",
    "                annot=True,\n",
    "                annot_kws={'fontsize':90},\n",
    "                fmt='d')\n",
    "        \n",
    "    axes[i,j].set_xlabel(\"Disease\", fontsize=90)\n",
    "\n",
    "    axes[i,j].set_ylabel(col,fontsize=90)\n",
    "    \n",
    "    axes[i,j].set_yticklabels(axes[i,j].get_yticklabels(),fontsize=50)\n",
    "    \n",
    "    axes[i,j].set_xticklabels([\"No CKD\",\"CKD\"],fontsize=50)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nothing interesting with the categorical variables. lets see if the numerical variable have any effect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting numerical variables with target variable\n",
    "\n",
    "figure, axes = plt.subplots(7, 2,figsize=(50, 100))\n",
    "figure.suptitle('\\nBox Plots of Numerical Variables with Target Variable', fontsize=100)\n",
    "\n",
    "for index, col in enumerate(num_cols):\n",
    "    \n",
    "    i,j = (index // 2), (index % 2)\n",
    "    \n",
    "    sns.boxenplot(data=ckd_df,y=ckd_df[col],x=ckd_df['chronic_kidney_disease'],\n",
    "                ax=axes[i,j],color='aquamarine')\n",
    "        \n",
    "    axes[i,j].set_xlabel(\"Disease\", fontsize=90)\n",
    "\n",
    "    axes[i,j].set_ylabel(col,fontsize=90)\n",
    "    \n",
    "    axes[i,j].set_yticklabels(axes[i,j].get_yticklabels(),fontsize=30)\n",
    "    axes[i,j].set_xticklabels([\"No CKD\",\"CKD\"],fontsize=30)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis 1 - Chi-Square Test for Impact of Specific Gravity on Chronic Kidney Disease\n",
    "contingency_table = pd.crosstab(ohe_data['specific_gravity'], ohe_data['chronic_kidney_disease:notckd'])\n",
    "chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "if p_value < 0.05:\n",
    "    print(\" Reject the null hypothesis\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis 2 - No significant difference in albumin levels between noCKD and CKD groups\n",
    "albumin_noCKD = ohe_data[ohe_data['chronic_kidney_disease:notckd'] == 1]['albumin']\n",
    "albumin_CKD = ohe_data[ohe_data['chronic_kidney_disease:notckd'] == 0]['albumin']\n",
    "\n",
    "# Perform Mann-Whitney U test\n",
    "statistic, p_value = mannwhitneyu(albumin_noCKD, albumin_CKD, alternative='two-sided')\n",
    "if p_value < 0.05:\n",
    "    print(\" Reject the null hypothesis\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis 3 - No significant difference in sugar levels between noCKD and CKD groups\n",
    "sugar_noCKD = ohe_data[ohe_data['chronic_kidney_disease:notckd'] == 1]['sugar']\n",
    "sugar_CKD = ohe_data[ohe_data['chronic_kidney_disease:notckd'] == 0]['sugar']\n",
    "\n",
    "# Perform Mann-Whitney U test\n",
    "statistic, p_value = mannwhitneyu(sugar_noCKD, sugar_CKD, alternative='two-sided')\n",
    "if p_value < 0.05:\n",
    "    print(\" Reject the null hypothesis\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hypothesis 4 - No significant difference in blood glucose levels between nockd and ckd\n",
    "blood_glucose_noCKD = ohe_data[ohe_data['chronic_kidney_disease:notckd'] == 1]['blood_glucose']\n",
    "blood_glucose_CKD = ohe_data[ohe_data['chronic_kidney_disease:notckd'] == 0]['blood_glucose']\n",
    "\n",
    "# Perform Mood's Median Test\n",
    "statistic, p_value, medians, table = median_test(blood_glucose_noCKD, blood_glucose_CKD)\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\" Reject the null hypothesis\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hypothesis 5 - No significant difference in blood urea levels between nockd and ckd\n",
    "blood_urea_noCKD = ohe_data[ohe_data['chronic_kidney_disease:notckd'] == 1]['blood_urea']\n",
    "blood_urea_CKD = ohe_data[ohe_data['chronic_kidney_disease:notckd'] == 0]['blood_urea']\n",
    "\n",
    "# Perform Mood's Median Test\n",
    "statistic, p_value, medians, table = median_test(blood_urea_noCKD, blood_urea_CKD)\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\" Reject the null hypothesis\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis 6 - No significant difference in serum creatinine levels between noCKD and CKD groups\n",
    "serum_noCKD = ohe_data[ohe_data['chronic_kidney_disease:notckd'] == 1]['serum_creatinine']\n",
    "serum_CKD = ohe_data[ohe_data['chronic_kidney_disease:notckd'] == 0]['serum_creatinine']\n",
    "\n",
    "# Perform Mann-Whitney U test\n",
    "statistic, p_value = mannwhitneyu(serum_noCKD, serum_CKD, alternative='two-sided')\n",
    "if p_value < 0.05:\n",
    "    print(\" Reject the null hypothesis\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hypothesis 7 - No significant difference in sodium levels between nockd and ckd\n",
    "sodium_noCKD = ohe_data[ohe_data['chronic_kidney_disease:notckd'] == 1]['sodium']\n",
    "sodium_CKD = ohe_data[ohe_data['chronic_kidney_disease:notckd'] == 0]['sodium']\n",
    "\n",
    "# Perform Mood's Median Test\n",
    "statistic, p_value, medians, table = median_test(sodium_noCKD, sodium_CKD)\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\" Reject the null hypothesis\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hypothesis 8 - No significant difference in haemoglobin levels between nockd and ckd\n",
    "\n",
    "haemoglobin_noCKD = ohe_data[ohe_data['chronic_kidney_disease:notckd'] == 1]['haemoglobin']\n",
    "haemoglobin_CKD = ohe_data[ohe_data['chronic_kidney_disease:notckd'] == 0]['haemoglobin']\n",
    "\n",
    "# Perform two-sample t-test\n",
    "statistic, p_value = ttest_ind(haemoglobin_noCKD, haemoglobin_CKD)\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\" Reject the null hypothesis\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hypothesis 9 - blood_glucose, sugar and the target variable\n",
    "\n",
    "# for blood_glucose and chronic_kidney_disease\n",
    "kw_statistic_blood_glucose, p_value_blood_glucose = kruskal(blood_glucose_noCKD, blood_glucose_CKD)\n",
    "\n",
    "# Sugar and chronic_kidney_disease\n",
    "kw_statistic_sugar, p_value_sugar = kruskal(sugar_noCKD, sugar_CKD)\n",
    "\n",
    "print(f\"Kruskal-Wallis - Blood Glucose: H = {kw_statistic_blood_glucose}, p = {p_value_blood_glucose}\")\n",
    "print(f\"Kruskal-Wallis - Sugar: H = {kw_statistic_sugar}, p = {p_value_sugar}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hypothesis 10 - packed_cell_volume, red_blood_cell_count and CKD\n",
    "\n",
    "\n",
    "pcv_noCKD = ohe_data[ohe_data['chronic_kidney_disease:notckd'] == 1]['packed_cell_volume']\n",
    "pcv_CKD = ohe_data[ohe_data['chronic_kidney_disease:notckd'] == 0]['packed_cell_volume']\n",
    "\n",
    "rbc_noCKD = ohe_data[ohe_data['chronic_kidney_disease:notckd'] == 1]['red_blood_cell_count']\n",
    "rbc_CKD = ohe_data[ohe_data['chronic_kidney_disease:notckd']==0]['red_blood_cell_count']\n",
    "\n",
    "# Perform two-sample t-test for packed_cell_volume and chronic_kidney_disease\n",
    "t_statistic_pcv, p_value_pcv = ttest_ind(pcv_noCKD, pcv_CKD)\n",
    "\n",
    "# Perform two-sample t-test for red_blood_cell_count and chronic_kidney_disease\n",
    "t_statistic_rbc, p_value_rbc = ttest_ind(rbc_noCKD, rbc_CKD)\n",
    "\n",
    "# Print results\n",
    "print(f\"Two-sample t-test - Packed Cell Volume: t = {t_statistic_pcv}, p = {p_value_pcv}\")\n",
    "print(f\"Two-sample t-test - Red Blood Cell Count: t = {t_statistic_rbc}, p = {p_value_rbc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling using standard scaler \n",
    "X = ohe_data.drop(\"chronic_kidney_disease:notckd\",axis=1,inplace=False)\n",
    "y = ohe_data[\"chronic_kidney_disease:notckd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_scaled_df = StandardScaler().fit_transform(ohe_data)\n",
    "scaled_df = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(scaled_df,y,test_size=0.3,random_state=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, auc, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = [3, 5, 7, 9, 11, 13, 15, 17, 19, 21]\n",
    "accuracy_scores = []\n",
    "\n",
    "for k in k_values:\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=k) # Create and fit the k-nearest neighbors model\n",
    "    knn_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_test = knn_model.predict(X_test)\n",
    "    knn_accuracy = accuracy_score(y_test,y_pred_test) #accuracy \n",
    "\n",
    "    print(f\"Results for k = {k}\")\n",
    "    print(f\"Test Accuracy of KNN is {knn_accuracy} \\n\")\n",
    "\n",
    "    print(f\"Confusion Matrix :- \\n{confusion_matrix(y_test, y_pred_test)}\\n\")\n",
    "    print(f\"Classification Report :- \\n{classification_report(y_test, y_pred_test)}\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    accuracy_scores.append(knn_accuracy)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_values, accuracy_scores, marker='o')\n",
    "plt.xlabel('K-Value')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('K-Value vs. Accuracy')\n",
    "plt.xticks(np.arange(1, 21))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#considering k=15 as optimal k-value\n",
    "knn_model = KNeighborsClassifier(n_neighbors=15)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn_model.predict(X_test)\n",
    "\n",
    "knn_accuracy = accuracy_score(y_test,y_pred)\n",
    "\n",
    "y_pred_probs = knn_model.predict_proba(X_test)[:, 1]  # Probabilities for positive class\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "confusion = confusion_matrix(y_test,y_pred)\n",
    "\n",
    "print(f\"AUC of ROC curve: {roc_auc}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=[\"noCKD\",\"CKD\"], yticklabels=[\"noCKD\",\"CKD\"],cbar=False)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(criterion='entropy',splitter='random')\n",
    "dt.fit(X_train,y_train)\n",
    "\n",
    "y_pred = dt.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "y_pred_probs = dt.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, _ = roc_curve(y_test,y_pred_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Test Accuracy is {dt_accuracy} \\n\")\n",
    "\n",
    "print(f\"Confusion Matrix :- \\n{confusion}\\n\")\n",
    "print(f\"Classification Report :- \\n {classification_report(y_test, dt.predict(X_test))}\")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"AUC of ROC curve: {roc_auc}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=[\"noCKD\",\"CKD\"], yticklabels=[\"noCKD\",\"CKD\"],cbar=False)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from matplotlib.legend_handler import HandlerLine2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets see how default random forest classifier performs\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train,y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test,y_pred)\n",
    "\n",
    "y_pred_probs = rf.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, _ = roc_curve(y_test,y_pred_probs)\n",
    "roc_auc = auc(fpr,tpr)\n",
    "\n",
    "print(f\"The accuracy score is {rf_accuracy}\")\n",
    "print(f\"the ROC AUC is {roc_auc}\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the optinum number of trees in forest \n",
    "n_estimators = [2,3,4,5,10,15,20,25,30,50, 100, 150, 200, 250, 300]\n",
    "train_results = []\n",
    "test_results = []\n",
    "for estimator in n_estimators:\n",
    "   rf = RandomForestClassifier(n_estimators=estimator, n_jobs=-1)\n",
    "   rf.fit(X_train, y_train)   \n",
    "   train_pred = rf.predict(X_train)   \n",
    "   fpr, tpr, _ = roc_curve(y_train, train_pred)\n",
    "   roc_auc = auc(fpr, tpr)\n",
    "   train_results.append(roc_auc)  \n",
    "   y_pred = rf.predict(X_test)   \n",
    "   fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "   roc_auc = auc(fpr, tpr)\n",
    "   test_results.append(roc_auc)\n",
    "   \n",
    "\n",
    "line1, = plt.plot(n_estimators, train_results, 'b', label=\"Train AUC\")\n",
    "line2, = plt.plot(n_estimators, test_results, 'r', label=\"Test AUC\")\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel(\"AUC score\")\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking model with recommended parameters\n",
    "rf = RandomForestClassifier(criterion = 'entropy', max_depth = 11, \n",
    "                            max_features = 'auto', min_samples_leaf = 2, \n",
    "                            min_samples_split = 3, n_estimators = 130)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# accuracy score, confusion matrix and classification report of random forest\n",
    "\n",
    "rf.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "y_pred_probs = rf.predict_proba(X_test)[:, 1]  # Probabilities for positive class\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "print(f\"Training Accuracy is {accuracy_score(y_train, rf.predict(X_train))}\")\n",
    "print(f\"Test Accuracy is {rf_accuracy} \\n\")\n",
    "\n",
    "print(f\"Confusion Matrix :- \\n{confusion_matrix(y_test, rf.predict(X_test))}\\n\")\n",
    "print(f\"Classification Report :- \\n {classification_report(y_test, rf.predict(X_test))}\")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"AUC of ROC curve: {roc_auc}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost/Adaptive Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training and fitting model, then printing scores\n",
    "ada = AdaBoostClassifier(base_estimator = dt)\n",
    "ada.fit(X_train, y_train)\n",
    "\n",
    "y_pred = ada.predict(X_test)\n",
    "ada_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "y_pred_probs = ada.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, _ = roc_curve(y_test,y_pred_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Test Accuracy is {ada_accuracy} \\n\")\n",
    "\n",
    "print(f\"Confusion Matrix :- \\n{confusion}\\n\")\n",
    "print(f\"Classification Report :- \\n {classification_report(y_test, ada.predict(X_test))}\")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"AUC of ROC curve: {roc_auc}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting ROC \n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=[\"noCKD\",\"CKD\"], yticklabels=[\"noCKD\",\"CKD\"],cbar=False)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Clasifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the optinum number of n_estimator\n",
    "n_estimators = [2,3,4,5,10,15,20,25,30,50]\n",
    "train_results = []\n",
    "test_results = []\n",
    "for estimator in n_estimators:\n",
    "   gb = GradientBoostingClassifier(n_estimators=estimator,criterion='squared_error')\n",
    "   gb.fit(X_train, y_train)   \n",
    "   train_pred = gb.predict(X_train)   \n",
    "   fpr, tpr, _ = roc_curve(y_train, train_pred)\n",
    "   roc_auc = auc(fpr, tpr)\n",
    "   train_results.append(roc_auc)  \n",
    "   y_pred = gb.predict(X_test)   \n",
    "   fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "   roc_auc = auc(fpr, tpr)\n",
    "   test_results.append(roc_auc)\n",
    "   \n",
    "\n",
    "line1, = plt.plot(n_estimators, train_results, 'b', label=\"Train AUC\")\n",
    "line2, = plt.plot(n_estimators, test_results, 'r', label=\"Test AUC\")\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel(\"AUC score\")\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier(n_estimators=25, validation_fraction=0.2, n_iter_no_change=10,\n",
    "                                learning_rate=0.1, max_depth=2)\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = gb.predict(X_test)\n",
    "gb_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "y_pred_probs = gb.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Test Accuracy is {gb_accuracy} \\n\")\n",
    "print(f\"Confusion Matrix:\\n{confusion}\\n\")\n",
    "print(f\"Classification Report:\\n{classification_report(y_test, gb.predict(X_test))}\")\n",
    "print(f\"AUC of ROC curve: {roc_auc}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting ROC \n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=[\"noCKD\",\"CKD\"], yticklabels=[\"noCKD\",\"CKD\"],cbar=False)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Boosting Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the optinum number of n_estimator\n",
    "n_estimators = [2,3,4,5,10,15,20,25,30,50,100,200,300]\n",
    "train_results = []\n",
    "test_results = []\n",
    "for estimator in n_estimators:\n",
    "   sgb = GradientBoostingClassifier(n_estimators=estimator,criterion='squared_error')\n",
    "   sgb.fit(X_train, y_train)   \n",
    "   train_pred = gb.predict(X_train)   \n",
    "   fpr, tpr, _ = roc_curve(y_train, train_pred)\n",
    "   roc_auc = auc(fpr, tpr)\n",
    "   train_results.append(roc_auc)  \n",
    "   y_pred = gb.predict(X_test)   \n",
    "   fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "   roc_auc = auc(fpr, tpr)\n",
    "   test_results.append(roc_auc)\n",
    "   \n",
    "\n",
    "line1, = plt.plot(n_estimators, train_results, 'b', label=\"Train AUC\")\n",
    "line2, = plt.plot(n_estimators, test_results, 'r', label=\"Test AUC\")\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel(\"AUC score\")\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgb = GradientBoostingClassifier(max_depth=2, subsample=1, max_features=1, n_estimators=25, random_state=42)\n",
    "sgb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = sgb.predict(X_test)\n",
    "sgb_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "y_pred_probs = sgb.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Test Accuracy is {sgb_accuracy} \\n\")\n",
    "print(f\"Confusion Matrix:\\n{confusion}\\n\")\n",
    "print(f\"Classification Report:\\n{classification_report(y_test, sgb.predict(X_test))}\")\n",
    "print(f\"AUC of ROC curve: {roc_auc}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting ROC \n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=[\"noCKD\",\"CKD\"], yticklabels=[\"noCKD\",\"CKD\"],cbar=False)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XgBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(objective = 'binary:logistic', learning_rate = 0.5, max_depth = 4, n_estimators = 200)\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgb.predict(X_test)\n",
    "xgb_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "y_pred_probs = xgb.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Test Accuracy is {xgb_accuracy} \\n\")\n",
    "print(f\"Confusion Matrix:\\n{confusion}\\n\")\n",
    "print(f\"Classification Report:\\n{classification_report(y_test, xgb.predict(X_test))}\")\n",
    "print(f\"AUC of ROC curve: {roc_auc}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting ROC \n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=[\"noCKD\",\"CKD\"], yticklabels=[\"noCKD\",\"CKD\"],cbar=False)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = CatBoostClassifier(iterations=7,verbose=0)\n",
    "cat.fit(X_train, y_train)\n",
    "\n",
    "y_pred = cat.predict(X_test)\n",
    "cat_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "y_pred_probs = cat.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Test Accuracy is {cat_accuracy} \\n\")\n",
    "print(f\"Confusion Matrix:\\n{confusion}\\n\")\n",
    "print(f\"Classification Report:\\n{classification_report(y_test, cat.predict(X_test))}\")\n",
    "print(f\"AUC of ROC curve: {roc_auc}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting ROC \n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=[\"noCKD\",\"CKD\"], yticklabels=[\"noCKD\",\"CKD\"],cbar=False)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et = ExtraTreesClassifier(n_estimators=100, max_depth=5, random_state=30)\n",
    "\n",
    "\n",
    "# Implement cross-validation to control overfitting\n",
    "y_pred_cv = cross_val_predict(et, X_train, y_train, cv=5)\n",
    "\n",
    "# Calculate accuracy score\n",
    "et_accuracy = accuracy_score(y_train, y_pred_cv)\n",
    "\n",
    "et.fit(X_train, y_train)\n",
    "\n",
    "y_pred = et.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "y_pred_probs = et.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Test Accuracy is {et_accuracy} \\n\")\n",
    "print(f\"Confusion Matrix:\\n{confusion}\\n\")\n",
    "print(f\"Classification Report:\\n{classification_report(y_test, et.predict(X_test))}\")\n",
    "print(f\"AUC of ROC curve: {roc_auc}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting ROC \n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=[\"noCKD\",\"CKD\"], yticklabels=[\"noCKD\",\"CKD\"],cbar=False)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = LGBMClassifier(learning_rate = 2, n_estimators=100,max_depth=3)\n",
    "\n",
    "# Implement cross-validation to control overfitting\n",
    "y_pred_cv = cross_val_predict(lgbm, X_train, y_train, cv=5)\n",
    "\n",
    "# Calculate accuracy score\n",
    "lgbm_accuracy = accuracy_score(y_train, y_pred_cv)\n",
    "\n",
    "lgbm.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lgbm.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "y_pred_probs = lgbm.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Test Accuracy is {lgbm_accuracy} \\n\")\n",
    "print(f\"Confusion Matrix:\\n{confusion}\\n\")\n",
    "print(f\"Classification Report:\\n{classification_report(y_test, lgbm.predict(X_test))}\")\n",
    "print(f\"AUC of ROC curve: {roc_auc}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=[\"noCKD\",\"CKD\"], yticklabels=[\"noCKD\",\"CKD\"],cbar=False)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.DataFrame({\n",
    "    'Model' : [ 'KNN', 'Decision Tree Classifier', 'Ada Boost Classifier',\n",
    "             'Gradient Boosting Classifier', 'Stochastic Gradient Boosting', 'XgBoost', 'Cat Boost', 'Extra Trees Classifier', 'LGBM Classifier'],\n",
    "    'Score' : [knn_accuracy, dt_accuracy, ada_accuracy, gb_accuracy, sgb_accuracy, xgb_accuracy, cat_accuracy, et_accuracy, lgbm_accuracy]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = performance.sort_values(by='Score', ascending=True).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(20, 15))\n",
    "sns.barplot(data=performance, x='Model', y='Score', palette=sns.color_palette(\"Blues\", len(performance)))\n",
    "plt.title('\\nAccuracy of Various Models\\n', fontsize=50)\n",
    "\n",
    "plt.xticks(rotation=45, ha='right', fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.xlabel('Model',fontsize=25)\n",
    "plt.ylabel('Score',fontsize=25)\n",
    "\n",
    "\n",
    "\n",
    "for index, row in performance.iterrows():\n",
    "    plt.text(index, row['Score'], round(row['Score'], 2), ha='center', va='bottom', fontsize=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
